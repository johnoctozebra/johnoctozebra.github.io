Welcome to Kenny's research server!

Phishing samples are hosted here for research purposes. These websites are scraped such that they can work locally (clone this repo if you wish. The main index.html is a convenience page to look to the first page of phishing pages (if first page was able to be scraped).  

A notes.txt is left in the top domain of every phishing page which notes down key observations or elements that could not be replicated from the original. 

It has been observed that all phishing sites use .php scripts on the server to get user information from HTML forms and it is up to that script that will redirect the user to a different page. Almost all of the time it's linear and goes to the next page, sometimes it will redirect the user to a legitimate site if it recieves malformed data in the forms. Since this code can not be scraped, the redirected HTML is scraped and all forms will redirect there instead of the PHP script. Note that only form code is changed (original is commented) so it is still possible that there is Javascript that talks to the phishing server. Although most likely safe since phishing domains are shut down very quickly, it's reccomended that you view these pages in an isolated envirotment such as a VM. 


 Only URLs on the same domain are scraped and saved locally. The purpose of this project is to replicate the look and behavior of phishing websites before they are taken down. The URL structure is followed verbatim (in the phish_sites directory). However the user often sees a simpler URL in an email such as http://antisnoredevicereview.com/wp-hal/ which redirects them to something more complicated like http://antisnoredevicereview.com/wp-hal/Login.php?sslchannel=true&sessionid=Iwe2xIkjQcEyUUWDyovOzrhWp2BJ2gELMTNjB7CrkhZebWSJknyTPPQfSrZUHDFuwtO8ArzVIz9Tv1DQ#. 

Phishing forms usually work in this order: 

	-> Present user with HTML form (or generated by JS)
	-> Optionally, softly validate fields so phisher can get valid data and for better presentation. 
	-> POST data to .php script, which simply saves or sends your data and then redirects user to the next phishing form or to the legitimate website of what the site is trying to impersonate. 
	-> Optionally dispaly more phishing forms and return to 1st step. 
	-> Optionally play animation showing that the website is doing work (upgrading account, deleting account, etc.) 
	-> Optionally (almost always) redirect user to the legitimate website such as dropbox.com. 

TODO:
- Add API to have server scrape web page and add it to to main page
- Add ability to delete web sites from web page GUI
- Add ability to create notes and tags for each website for research purposes. 



- Kenny

